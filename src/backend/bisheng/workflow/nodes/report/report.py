import io
import re
import os
import tempfile
import requests
from urllib.parse import urlparse, unquote
from uuid import uuid4
import hashlib
from loguru import logger
from typing import Dict, Tuple, Any

from bisheng.utils.minio_client import MinioClient
from bisheng.utils.docx_temp import DocxTemplateRender
from bisheng.workflow.callback.event import OutputMsgData
from bisheng.workflow.nodes.base import BaseNode


class ReportNode(BaseNode):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._report_info = self.node_params["report_info"]
        self._version_key = self._report_info["version_key"].split("_")[0]
        self._object_name = f"workflow/report/{self._version_key}.docx"
        self._file_name = self._report_info["file_name"] if self._report_info["file_name"] else "tmp_report.docx"
        if not self._file_name.endswith(".docx"):
            self._file_name += ".docx"
        self._minio_client = MinioClient()
        # å­˜å‚¨ä¸‹è½½çš„æ–‡ä»¶ä¿¡æ¯ï¼Œç”¨äºåç»­æ’å…¥æ–‡æ¡£
        self._downloaded_files: Dict[str, str] = {}
        # å…¨å±€å ä½ç¬¦è®¡æ•°å™¨ï¼Œç¡®ä¿å ä½ç¬¦å”¯ä¸€æ€§
        self._global_placeholder_counter = 0

    def _get_unique_placeholder_id(self) -> int:
        """è·å–å”¯ä¸€çš„å ä½ç¬¦ID"""
        placeholder_id = self._global_placeholder_counter
        self._global_placeholder_counter += 1
        return placeholder_id

    def _bind_markdown_with_images(self, markdown_content: str, image_files: list, resources: dict) -> str:
        """
        å°†markdownå†…å®¹ä¸­çš„å›¾ç‰‡å¼•ç”¨ä¸å®é™…å›¾ç‰‡æ–‡ä»¶å»ºç«‹ç»‘å®šå…³ç³»

        Args:
            markdown_content: markdownæ–‡æœ¬å†…å®¹
            image_files: ç›¸å…³çš„å›¾ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            resources: èµ„æºä¿¡æ¯å­—å…¸

        Returns:
            str: å¤„ç†åçš„markdownå†…å®¹ï¼ˆå›¾ç‰‡å¼•ç”¨å·²æ›¿æ¢ä¸ºå ä½ç¬¦ï¼‰
        """
        if not image_files or not isinstance(image_files, list):
            return markdown_content

        processed_content = markdown_content

        # æå–markdownä¸­çš„æ‰€æœ‰å›¾ç‰‡å¼•ç”¨
        markdown_image_pattern = r"!\[([^\]]*)\]\(([^)]+)\)"
        image_matches = re.findall(markdown_image_pattern, processed_content, re.IGNORECASE)

        logger.info(f"åœ¨markdownå†…å®¹ä¸­æ‰¾åˆ° {len(image_matches)} ä¸ªå›¾ç‰‡å¼•ç”¨")

        # ä¸ºæ¯ä¸ªå›¾ç‰‡å¼•ç”¨åŒ¹é…å¯¹åº”çš„å®é™…å›¾ç‰‡æ–‡ä»¶
        for alt_text, img_path in image_matches:
            # å°è¯•åŒ¹é…å®é™…çš„å›¾ç‰‡æ–‡ä»¶
            matched_file = self._match_image_file(img_path, image_files)

            if matched_file:
                # åˆ›å»ºå ä½ç¬¦
                placeholder = f"__IMAGE_PLACEHOLDER_{self._get_unique_placeholder_id()}__"

                # æ·»åŠ åˆ°èµ„æºåˆ—è¡¨
                resources["images"].append(
                    {
                        "original_path": img_path,
                        "local_path": matched_file,
                        "alt_text": alt_text or "å›¾ç‰‡",
                        "placeholder": placeholder,
                        "type": "bound",
                        "original_text": f"![{alt_text}]({img_path})",
                    }
                )

                # æ›¿æ¢markdownä¸­çš„å›¾ç‰‡å¼•ç”¨ä¸ºå ä½ç¬¦
                original_ref = f"![{alt_text}]({img_path})"
                processed_content = processed_content.replace(original_ref, placeholder)

                logger.info(f"ç»‘å®šæˆåŠŸ: markdownå¼•ç”¨ '{img_path}' -> å®é™…æ–‡ä»¶ '{matched_file}'")
            else:
                logger.warning(f"æ— æ³•ä¸ºmarkdownå›¾ç‰‡å¼•ç”¨ '{img_path}' æ‰¾åˆ°åŒ¹é…çš„å®é™…æ–‡ä»¶")

        return processed_content

    def _match_image_file(self, markdown_ref: str, image_files: list) -> str:
        """
        ä¸ºmarkdownä¸­çš„å›¾ç‰‡å¼•ç”¨åŒ¹é…å®é™…çš„å›¾ç‰‡æ–‡ä»¶

        Args:
            markdown_ref: markdownä¸­çš„å›¾ç‰‡å¼•ç”¨è·¯å¾„
            image_files: å¯ç”¨çš„å›¾ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨

        Returns:
            str: åŒ¹é…çš„å›¾ç‰‡æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ²¡æœ‰åŒ¹é…è¿”å›None
        """
        if not markdown_ref or not image_files:
            return None

        # æå–æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
        ref_filename = os.path.basename(markdown_ref)

        # ç­–ç•¥1: å®Œå…¨åŒ¹é…æ–‡ä»¶å
        for img_file in image_files:
            if os.path.basename(img_file) == ref_filename:
                if os.path.exists(img_file):
                    logger.info(f"å®Œå…¨åŒ¹é…: {ref_filename} -> {img_file}")
                    return img_file

        # ç­–ç•¥2: åŒ¹é…ä¸å«æ‰©å±•åçš„æ–‡ä»¶å
        ref_name_without_ext = os.path.splitext(ref_filename)[0]
        for img_file in image_files:
            img_name_without_ext = os.path.splitext(os.path.basename(img_file))[0]
            if img_name_without_ext == ref_name_without_ext:
                if os.path.exists(img_file):
                    logger.info(f"åç§°åŒ¹é…: {ref_name_without_ext} -> {img_file}")
                    return img_file

        # ç­–ç•¥3: æ£€æŸ¥markdownå¼•ç”¨æ˜¯å¦æœ¬èº«å°±æ˜¯å®Œæ•´è·¯å¾„
        if os.path.exists(markdown_ref) and markdown_ref in image_files:
            logger.info(f"è·¯å¾„åŒ¹é…: {markdown_ref}")
            return markdown_ref

        # ç­–ç•¥4: æ¨¡ç³ŠåŒ¹é… - å¦‚æœåªæœ‰ä¸€ä¸ªå›¾ç‰‡æ–‡ä»¶ï¼Œå‡è®¾å®ƒä»¬åŒ¹é…
        available_files = [f for f in image_files if os.path.exists(f)]
        if len(available_files) == 1:
            logger.info(f"å•æ–‡ä»¶åŒ¹é…: {markdown_ref} -> {available_files[0]} (åªæœ‰ä¸€ä¸ªå¯ç”¨å›¾ç‰‡)")
            return available_files[0]

        return None

    def _is_valid_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„URL"""
        try:
            result = urlparse(url)
            return all([result.scheme, result.netloc])
        except ValueError:
            return False

    def _download_file(self, url: str) -> Tuple[str, bool]:
        """
        ä¸‹è½½æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•

        Args:
            url: æ–‡ä»¶URL

        Returns:
            tuple: (æœ¬åœ°æ–‡ä»¶è·¯å¾„, æ˜¯å¦ä¸‹è½½æˆåŠŸ)
        """
        try:
            # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                "(KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }

            response = requests.get(url, headers=headers, timeout=30, verify=False)
            response.raise_for_status()

            # è·å–æ–‡ä»¶å
            content_disposition = response.headers.get("Content-Disposition", "")
            filename = ""
            if content_disposition:
                filename = unquote(content_disposition).split("filename=")[-1].strip("\"'")
            if not filename:
                filename = unquote(urlparse(url).path.split("/")[-1])
            if not filename:
                # æ ¹æ®Content-Typeæ¨æ–­æ‰©å±•å
                content_type = response.headers.get("Content-Type", "").lower()
                if "image/png" in content_type:
                    filename = f"{uuid4().hex}.png"
                elif "image/jpeg" in content_type or "image/jpg" in content_type:
                    filename = f"{uuid4().hex}.jpg"
                elif "image/bmp" in content_type:
                    filename = f"{uuid4().hex}.bmp"
                elif "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" in content_type:
                    filename = f"{uuid4().hex}.xlsx"
                elif "application/vnd.ms-excel" in content_type:
                    filename = f"{uuid4().hex}.xls"
                else:
                    filename = f"{uuid4().hex}.dat"

            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_dir = tempfile.gettempdir()
            temp_file = os.path.join(temp_dir, filename)

            with open(temp_file, "wb") as f:
                f.write(response.content)

            logger.info(f"æˆåŠŸä¸‹è½½æ–‡ä»¶: {url} -> {temp_file}")
            return temp_file, True

        except Exception as e:
            logger.error(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {url}, é”™è¯¯: {str(e)}")
            return "", False

    def _download_minio_file(self, minio_path: str) -> Tuple[str, bool]:
        """
        ä»MinIOä¸‹è½½æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•

        Args:
            minio_path: MinIOæ–‡ä»¶è·¯å¾„

        Returns:
            tuple: (æœ¬åœ°æ–‡ä»¶è·¯å¾„, æ˜¯å¦ä¸‹è½½æˆåŠŸ)
        """
        try:
            # è§£æMinIOè·¯å¾„
            bucket_name = None
            object_name = None

            if minio_path.startswith("minio://"):
                # æ ¼å¼: minio://bucket/object/name
                parts = minio_path[8:].split("/", 1)
                if len(parts) == 2:
                    bucket_name, object_name = parts
                else:
                    object_name = parts[0]
                    bucket_name = self._minio_client.bucket  # é»˜è®¤bucket
            elif minio_path.startswith("/bisheng/"):
                # æ ¼å¼: /bisheng/object/name
                bucket_name = self._minio_client.bucket
                object_name = minio_path[9:]  # ç§»é™¤ '/bisheng/'
            elif minio_path.startswith("/tmp-dir/"):
                # æ ¼å¼: /tmp-dir/object/name
                bucket_name = self._minio_client.tmp_bucket
                object_name = minio_path[9:]  # ç§»é™¤ '/tmp-dir/'
            else:
                # å°è¯•ä½œä¸ºå®Œæ•´URLå¤„ç†
                if self._is_valid_url(minio_path):
                    return self._download_file(minio_path)
                else:
                    logger.error(f"æ— æ³•è§£æMinIOè·¯å¾„: {minio_path}")
                    return "", False

            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not self._minio_client.object_exists(bucket_name, object_name):
                logger.error(f"MinIOæ–‡ä»¶ä¸å­˜åœ¨: {bucket_name}/{object_name}")
                return "", False

            # ä¸‹è½½æ–‡ä»¶å†…å®¹
            file_content = self._minio_client.get_object(bucket_name, object_name)

            # ç”Ÿæˆä¸´æ—¶æ–‡ä»¶å
            file_ext = os.path.splitext(object_name)[1] or ".dat"
            filename = f"{uuid4().hex}{file_ext}"
            temp_dir = tempfile.gettempdir()
            temp_file = os.path.join(temp_dir, filename)

            # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            with open(temp_file, "wb") as f:
                f.write(file_content)

            logger.info(f"æˆåŠŸä»MinIOä¸‹è½½æ–‡ä»¶: {minio_path} -> {temp_file}")
            return temp_file, True

        except Exception as e:
            logger.error(f"ä»MinIOä¸‹è½½æ–‡ä»¶å¤±è´¥: {minio_path}, é”™è¯¯: {str(e)}")
            return "", False

    def _extract_and_download_resources(
        self, value: str, related_image_files: list = None
    ) -> Tuple[str, Dict[str, Any]]:
        """
        ä»å˜é‡å€¼ä¸­æå–å¹¶ä¸‹è½½èµ„æºæ–‡ä»¶

        Args:
            value: åŸå§‹å˜é‡å€¼ï¼ˆå­—ç¬¦ä¸²æˆ–æ•°ç»„ï¼‰
            related_image_files: ç›¸å…³çš„å›¾ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œç”¨äºå»ºç«‹ç»‘å®šå…³ç³»

        Returns:
            tuple: (å¤„ç†åçš„å˜é‡å€¼, èµ„æºä¿¡æ¯å­—å…¸)
        """
        # ä¼˜å…ˆå¤„ç†æ•°ç»„æ ¼å¼ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if isinstance(value, list):
            processed_items = []
            resources = {"images": [], "excel_files": [], "csv_files": [], "markdown_tables": []}

            for item in value:
                if isinstance(item, str):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯Windowsè·¯å¾„ï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡
                    if item.startswith(("C:", "D:", "E:")) or "\\" in item:
                        logger.warning(f"è·³è¿‡Windowsè·¯å¾„: {item}")
                        continue

                    # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡æ–‡ä»¶è·¯å¾„ï¼ˆæ•°ç»„ä¸­çš„é¡¹ç›®é€šå¸¸æ˜¯æ–‡ä»¶è·¯å¾„ï¼‰
                    if any(item.lower().endswith(ext) for ext in [".png", ".jpg", ".jpeg", ".bmp"]):
                        if os.path.exists(item):
                            placeholder = f"__IMAGE_PLACEHOLDER_{self._get_unique_placeholder_id()}__"
                            resources["images"].append(
                                {
                                    "original_path": item,
                                    "local_path": item,
                                    "alt_text": "å›¾ç‰‡",
                                    "placeholder": placeholder,
                                    "type": "local",
                                    "original_text": f"![å›¾ç‰‡]({item})",
                                }
                            )
                            processed_items.append(placeholder)
                            logger.info(f"è¯†åˆ«åˆ°æ•°ç»„ä¸­çš„æœ¬åœ°å›¾ç‰‡æ–‡ä»¶: {item}")
                        else:
                            logger.warning(f"æ•°ç»„ä¸­çš„å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {item}")
                    else:
                        # å¯¹éå›¾ç‰‡é¡¹ç›®è¿›è¡Œå¸¸è§„èµ„æºæå–
                        processed_item, item_resources = self._extract_and_download_resources(item)
                        processed_items.append(processed_item)
                        # åˆå¹¶èµ„æº
                        resources["images"].extend(item_resources.get("images", []))
                        resources["excel_files"].extend(item_resources.get("excel_files", []))
                        resources["csv_files"].extend(item_resources.get("csv_files", []))
                        resources["markdown_tables"].extend(item_resources.get("markdown_tables", []))
                else:
                    processed_items.append(str(item))

            return "\n".join(processed_items), resources

        if not isinstance(value, str):
            return str(value), {}

        # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        patterns = {
            # å›¾ç‰‡æ¨¡å¼ - æŒ‰ä¼˜å…ˆçº§æ’åº
            "markdown_image": r"!\[([^\]]*)\]\(([^)]+\.(?:png|jpg|jpeg|bmp)(?:\?[^)]*)?)\)",  # Markdownæ ¼å¼å›¾ç‰‡ï¼ˆæ”¯æŒæŸ¥è¯¢å‚æ•°ï¼‰
            "local_image": r"([^\s]*\.(?:png|jpg|jpeg|bmp))",  # æœ¬åœ°è·¯å¾„å›¾ç‰‡ï¼ˆåµŒå…¥æ–‡æœ¬ä¸­ï¼‰
            "minio_image": r"((?:minio://|/bisheng/|/tmp-dir/)[^\s]*\.(?:png|jpg|jpeg|bmp))",  # MinIOè·¯å¾„å›¾ç‰‡
            "http_image": r"(https?://[^\s\u4e00-\u9fff]*\.(?:png|jpg|jpeg|bmp)(?:\?[^\s\u4e00-\u9fff]*)?)",
            # HTTP/HTTPSå›¾ç‰‡ï¼ˆæ”¯æŒæŸ¥è¯¢å‚æ•°ï¼Œæ’é™¤ä¸­æ–‡å­—ç¬¦ï¼‰
            # è¡¨æ ¼æ¨¡å¼
            "excel_file": r"([^\s]*\.(?:xls|xlsx)(?:\?[^\s]*)?)",  # Excelæ–‡ä»¶ï¼ˆåµŒå…¥æ–‡æœ¬ä¸­ï¼Œæ”¯æŒæŸ¥è¯¢å‚æ•°ï¼‰
            "csv_file": r"([^\s\u4e00-\u9fff]*\.csv(?:\?[^\s]*)?)",  # CSVæ–‡ä»¶ï¼ˆåµŒå…¥æ–‡æœ¬ä¸­ï¼Œæ”¯æŒæŸ¥è¯¢å‚æ•°ï¼Œæ’é™¤ä¸­æ–‡å­—ç¬¦ï¼‰
            "markdown_table": r"(\|[^\r\n]*\|(?:\r?\n\|[^\r\n]*\|)+)",  # Markdownè¡¨æ ¼ï¼ˆä¿®å¤ç‰ˆï¼Œæ­£ç¡®å¤„ç†è¡¨æ ¼å†…çš„|ç¬¦å·ï¼‰
        }

        processed_value = value
        resources = {"images": [], "excel_files": [], "csv_files": [], "markdown_tables": []}

        # ç”¨äºè·Ÿè¸ªå·²å¤„ç†çš„è·¯å¾„ï¼Œé¿å…é‡å¤
        processed_paths = set()

        # ç‰¹æ®Šå¤„ç†ï¼šå»ºç«‹markdownå†…å®¹å’Œç›¸å…³å›¾ç‰‡æ–‡ä»¶çš„ç»‘å®šå…³ç³»
        markdown_binding_applied = False
        if related_image_files and isinstance(related_image_files, list):
            logger.info(f"å¼€å§‹å¤„ç†markdownå†…å®¹çš„å›¾ç‰‡ç»‘å®šï¼Œå…³è”å›¾ç‰‡æ•°é‡: {len(related_image_files)}")
            processed_value = self._bind_markdown_with_images(processed_value, related_image_files, resources)
            markdown_binding_applied = True
            logger.info("ç»‘å®šå¤„ç†å®Œæˆï¼Œè·³è¿‡åç»­çš„å¸¸è§„markdownå›¾ç‰‡å¤„ç†")

        # 1. å¤„ç†å›¾ç‰‡ - æŒ‰ä¼˜å…ˆçº§æ’åº
        # 1.1 Markdownæ ¼å¼å›¾ç‰‡ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰- ä»…åœ¨æœªè¿›è¡Œç»‘å®šå¤„ç†æ—¶æ‰§è¡Œ
        if not markdown_binding_applied:
            markdown_images = re.findall(patterns["markdown_image"], processed_value, re.IGNORECASE)
            for alt_text, img_path in markdown_images:
                if img_path not in processed_paths:
                    processed_paths.add(img_path)

                    if not self._is_valid_url(img_path):  # æœ¬åœ°è·¯å¾„
                        if os.path.exists(img_path):
                            # æœ¬åœ°æ–‡ä»¶å­˜åœ¨ï¼Œè®°å½•åˆ°èµ„æºåˆ—è¡¨
                            placeholder = f"__IMAGE_PLACEHOLDER_{self._get_unique_placeholder_id()}__"
                            resources["images"].append(
                                {
                                    "original_path": img_path,
                                    "local_path": img_path,
                                    "alt_text": alt_text,
                                    "placeholder": placeholder,
                                    "type": "local",
                                    "original_text": f"![{alt_text}]({img_path})",
                                }
                            )
                            # åœ¨æ–‡æ¡£ä¸­ç”¨å ä½ç¬¦æ›¿æ¢
                            processed_value = processed_value.replace(f"![{alt_text}]({img_path})", placeholder)
                            logger.info(f"è¯†åˆ«åˆ°æœ¬åœ°Markdownå›¾ç‰‡: {img_path}")
                        else:
                            logger.warning(f"æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
                    else:
                        # ç½‘ç»œå›¾ç‰‡ï¼Œä¸‹è½½å¤„ç†
                        local_path, success = self._download_file(img_path)
                        placeholder = f"__IMAGE_PLACEHOLDER_{self._get_unique_placeholder_id()}__"

                        if success:
                            resources["images"].append(
                                {
                                    "original_path": img_path,
                                    "local_path": local_path,
                                    "alt_text": alt_text,
                                    "placeholder": placeholder,
                                    "type": "downloaded",
                                    "original_text": f"![{alt_text}]({img_path})",
                                }
                            )
                            logger.info(f"ç½‘ç»œMarkdownå›¾ç‰‡ä¸‹è½½æˆåŠŸ: {img_path} -> {local_path}")
                        else:
                            resources["images"].append(
                                {
                                    "original_path": img_path,
                                    "local_path": img_path,
                                    "alt_text": alt_text,
                                    "placeholder": placeholder,
                                    "type": "failed",
                                    "original_text": f"![{alt_text}]({img_path})",
                                }
                            )
                            logger.warning(f"ç½‘ç»œMarkdownå›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_path}")

                        processed_value = processed_value.replace(f"![{alt_text}]({img_path})", placeholder)

        # 1.2 MinIOè·¯å¾„å›¾ç‰‡ - ä¸‹è½½åˆ°æœ¬åœ°
        minio_images = re.findall(patterns["minio_image"], processed_value, re.IGNORECASE)
        for img_path in minio_images:
            if img_path not in processed_paths:
                processed_paths.add(img_path)
                # ä¸‹è½½MinIOå›¾ç‰‡åˆ°æœ¬åœ°
                local_path, success = self._download_minio_file(img_path)
                placeholder = f"__IMAGE_PLACEHOLDER_{self._get_unique_placeholder_id()}__"

                if success:
                    resources["images"].append(
                        {
                            "original_path": img_path,
                            "local_path": local_path,
                            "alt_text": "å›¾ç‰‡",
                            "placeholder": placeholder,
                            "type": "downloaded",
                            "original_text": img_path,
                        }
                    )
                    logger.info(f"MinIOå›¾ç‰‡ä¸‹è½½æˆåŠŸ: {img_path} -> {local_path}")
                else:
                    resources["images"].append(
                        {
                            "original_path": img_path,
                            "local_path": img_path,
                            "alt_text": "å›¾ç‰‡",
                            "placeholder": placeholder,
                            "type": "failed",
                            "original_text": img_path,
                        }
                    )
                    logger.warning(f"MinIOå›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_path}")

                processed_value = processed_value.replace(img_path, placeholder)

        # 1.3 HTTP/HTTPSå›¾ç‰‡é“¾æ¥
        http_images = re.findall(patterns["http_image"], processed_value, re.IGNORECASE)
        for img_url in http_images:
            if img_url not in processed_paths:
                processed_paths.add(img_url)
                local_path, success = self._download_file(img_url)
                placeholder = f"__IMAGE_PLACEHOLDER_{self._get_unique_placeholder_id()}__"

                if success:
                    resources["images"].append(
                        {
                            "original_path": img_url,
                            "local_path": local_path,
                            "alt_text": "å›¾ç‰‡",
                            "placeholder": placeholder,
                            "type": "downloaded",
                            "original_text": img_url,
                        }
                    )
                    logger.info(f"ç½‘ç»œå›¾ç‰‡ä¸‹è½½æˆåŠŸ: {img_url} -> {local_path}")
                else:
                    resources["images"].append(
                        {
                            "original_path": img_url,
                            "local_path": img_url,
                            "alt_text": "å›¾ç‰‡",
                            "placeholder": placeholder,
                            "type": "failed",
                            "original_text": img_url,
                        }
                    )
                    logger.warning(f"ç½‘ç»œå›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_url}")

                processed_value = processed_value.replace(img_url, placeholder)

        # 1.4 æœ¬åœ°è·¯å¾„å›¾ç‰‡ï¼ˆæœ€åå¤„ç†ï¼Œé¿å…è¯¯åŒ¹é…ï¼‰
        local_images = re.findall(patterns["local_image"], processed_value, re.IGNORECASE)
        for img_path in local_images:
            # è¿‡æ»¤æ‰å·²å¤„ç†çš„è·¯å¾„å’Œæ˜æ˜¾ä¸æ˜¯è·¯å¾„çš„æ–‡æœ¬
            if (
                img_path not in processed_paths
                and ("/" in img_path or "\\" in img_path)
                and not self._is_valid_url(img_path)  # å¿…é¡»åŒ…å«è·¯å¾„åˆ†éš”ç¬¦
                and not img_path.startswith("minio://")
                and not img_path.startswith("/bisheng/")
                and not img_path.startswith("/tmp-dir/")
            ):
                processed_paths.add(img_path)
                if os.path.exists(img_path):
                    placeholder = f"__IMAGE_PLACEHOLDER_{self._get_unique_placeholder_id()}__"
                    resources["images"].append(
                        {
                            "original_path": img_path,
                            "local_path": img_path,
                            "alt_text": "å›¾ç‰‡",
                            "placeholder": placeholder,
                            "type": "local",
                            "original_text": img_path,
                        }
                    )
                    processed_value = processed_value.replace(img_path, placeholder)
                    logger.info(f"è¯†åˆ«åˆ°æœ¬åœ°å›¾ç‰‡: {img_path}")
                else:
                    logger.warning(f"æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {img_path}")

        # 2. å¤„ç†Excelè¡¨æ ¼æ–‡ä»¶
        excel_files = re.findall(patterns["excel_file"], processed_value, re.IGNORECASE)
        for excel_path in excel_files:
            if excel_path not in processed_paths:
                processed_paths.add(excel_path)
                placeholder = f"__EXCEL_PLACEHOLDER_{self._get_unique_placeholder_id()}__"

                if self._is_valid_url(excel_path):
                    # ç½‘ç»œExcelæ–‡ä»¶
                    local_path, success = self._download_file(excel_path)
                    if success:
                        resources["excel_files"].append(
                            {
                                "original_path": excel_path,
                                "local_path": local_path,
                                "placeholder": placeholder,
                                "type": "downloaded",
                                "original_text": excel_path,
                            }
                        )
                        logger.info(f"Excelæ–‡ä»¶ä¸‹è½½æˆåŠŸ: {excel_path} -> {local_path}")
                    else:
                        resources["excel_files"].append(
                            {
                                "original_path": excel_path,
                                "local_path": excel_path,
                                "placeholder": placeholder,
                                "type": "failed",
                                "original_text": excel_path,
                            }
                        )
                        logger.warning(f"Excelæ–‡ä»¶ä¸‹è½½å¤±è´¥: {excel_path}")
                elif (
                    excel_path.startswith("/bisheng/")
                    or excel_path.startswith("/tmp-dir/")
                    or excel_path.startswith("minio://")
                ):
                    # MinIO Excelæ–‡ä»¶
                    local_path, success = self._download_minio_file(excel_path)
                    if success:
                        resources["excel_files"].append(
                            {
                                "original_path": excel_path,
                                "local_path": local_path,
                                "placeholder": placeholder,
                                "type": "downloaded",
                                "original_text": excel_path,
                            }
                        )
                        logger.info(f"MinIO Excelæ–‡ä»¶ä¸‹è½½æˆåŠŸ: {excel_path} -> {local_path}")
                    else:
                        resources["excel_files"].append(
                            {
                                "original_path": excel_path,
                                "local_path": excel_path,
                                "placeholder": placeholder,
                                "type": "failed",
                                "original_text": excel_path,
                            }
                        )
                        logger.warning(f"MinIO Excelæ–‡ä»¶ä¸‹è½½å¤±è´¥: {excel_path}")
                else:
                    # æœ¬åœ°Excelæ–‡ä»¶
                    if os.path.exists(excel_path):
                        resources["excel_files"].append(
                            {
                                "original_path": excel_path,
                                "local_path": excel_path,
                                "placeholder": placeholder,
                                "type": "local",
                                "original_text": excel_path,
                            }
                        )
                        logger.info(f"è¯†åˆ«åˆ°æœ¬åœ°Excelæ–‡ä»¶: {excel_path}")
                    else:
                        resources["excel_files"].append(
                            {
                                "original_path": excel_path,
                                "local_path": excel_path,
                                "placeholder": placeholder,
                                "type": "missing",
                                "original_text": excel_path,
                            }
                        )
                        logger.warning(f"æœ¬åœ°Excelæ–‡ä»¶ä¸å­˜åœ¨: {excel_path}")

                processed_value = processed_value.replace(excel_path, placeholder)

        # 3. å¤„ç†CSVè¡¨æ ¼æ–‡ä»¶
        csv_files = re.findall(patterns["csv_file"], processed_value, re.IGNORECASE)
        for csv_path in csv_files:
            if csv_path not in processed_paths:
                processed_paths.add(csv_path)
                placeholder = f"__CSV_PLACEHOLDER_{self._get_unique_placeholder_id()}__"

                if self._is_valid_url(csv_path):
                    # ç½‘ç»œCSVæ–‡ä»¶
                    local_path, success = self._download_file(csv_path)
                    if success:
                        resources["csv_files"].append(
                            {
                                "original_path": csv_path,
                                "local_path": local_path,
                                "placeholder": placeholder,
                                "type": "downloaded",
                                "original_text": csv_path,
                            }
                        )
                        logger.info(f"CSVæ–‡ä»¶ä¸‹è½½æˆåŠŸ: {csv_path} -> {local_path}")
                    else:
                        resources["csv_files"].append(
                            {
                                "original_path": csv_path,
                                "local_path": csv_path,
                                "placeholder": placeholder,
                                "type": "failed",
                                "original_text": csv_path,
                            }
                        )
                        logger.warning(f"CSVæ–‡ä»¶ä¸‹è½½å¤±è´¥: {csv_path}")
                elif (
                    csv_path.startswith("/bisheng/")
                    or csv_path.startswith("/tmp-dir/")
                    or csv_path.startswith("minio://")
                ):
                    # MinIO CSVæ–‡ä»¶
                    local_path, success = self._download_minio_file(csv_path)
                    if success:
                        resources["csv_files"].append(
                            {
                                "original_path": csv_path,
                                "local_path": local_path,
                                "placeholder": placeholder,
                                "type": "downloaded",
                                "original_text": csv_path,
                            }
                        )
                        logger.info(f"MinIO CSVæ–‡ä»¶ä¸‹è½½æˆåŠŸ: {csv_path} -> {local_path}")
                    else:
                        resources["csv_files"].append(
                            {
                                "original_path": csv_path,
                                "local_path": csv_path,
                                "placeholder": placeholder,
                                "type": "failed",
                                "original_text": csv_path,
                            }
                        )
                        logger.warning(f"MinIO CSVæ–‡ä»¶ä¸‹è½½å¤±è´¥: {csv_path}")
                else:
                    # æœ¬åœ°CSVæ–‡ä»¶
                    if os.path.exists(csv_path):
                        resources["csv_files"].append(
                            {
                                "original_path": csv_path,
                                "local_path": csv_path,
                                "placeholder": placeholder,
                                "type": "local",
                                "original_text": csv_path,
                            }
                        )
                        logger.info(f"è¯†åˆ«åˆ°æœ¬åœ°CSVæ–‡ä»¶: {csv_path}")
                    else:
                        resources["csv_files"].append(
                            {
                                "original_path": csv_path,
                                "local_path": csv_path,
                                "placeholder": placeholder,
                                "type": "missing",
                                "original_text": csv_path,
                            }
                        )
                        logger.warning(f"æœ¬åœ°CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")

                processed_value = processed_value.replace(csv_path, placeholder)

        # 4. å¤„ç†Markdownè¡¨æ ¼ï¼ˆä¿æŒä¸å˜ï¼‰
        markdown_tables = re.findall(patterns["markdown_table"], processed_value, re.MULTILINE)
        for table_content in markdown_tables:
            placeholder = f"__TABLE_PLACEHOLDER_{self._get_unique_placeholder_id()}__"
            resources["markdown_tables"].append(
                {
                    "content": table_content,
                    "placeholder": placeholder,
                    "type": "markdown",
                    "original_text": table_content,
                }
            )
            processed_value = processed_value.replace(table_content, placeholder)
            logger.info(f"è¯†åˆ«åˆ°Markdownè¡¨æ ¼ï¼Œè¡Œæ•°: {table_content.count('|')}")

        return processed_value, resources

    def _run(self, unique_id: str):
        # ä¸‹è½½æŠ¥å‘Šæ¨¡æ¿æ–‡ä»¶
        if not self._minio_client.object_exists(self._minio_client.bucket, self._object_name):
            raise Exception(f"{self.name}èŠ‚ç‚¹æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆç¼–è¾‘å¯¹åº”çš„æŠ¥å‘Šæ¨¡æ¿")
        file_content = self._minio_client.get_object(self._minio_client.bucket, self._object_name)
        doc_parse = DocxTemplateRender(file_content=io.BytesIO(file_content))

        # è·å–æ‰€æœ‰çš„èŠ‚ç‚¹å˜é‡
        all_variables = self.graph_state.get_all_variables()
        template_def = []
        all_resources = {"images": [], "excel_files": [], "csv_files": [], "markdown_tables": []}

        # ç‰¹æ®Šå¤„ç†ï¼šå»ºç«‹markdownå†…å®¹å’Œå›¾ç‰‡æ–‡ä»¶çš„ç»‘å®šå…³ç³»
        dialog_files_content = all_variables.get("dialog_files_content")
        dialog_image_files = all_variables.get("dialog_image_files")

        # å¤„ç†æ¯ä¸ªå˜é‡å€¼
        for key, value in all_variables.items():
            # è®°å½•æ•°ç»„å˜é‡ç±»å‹ç”¨äºè°ƒè¯•
            if isinstance(value, list):
                logger.info(f"å¤„ç†æ•°ç»„å˜é‡: {key}, åŒ…å« {len(value)} ä¸ªé¡¹ç›®")

            # å¯¹äºåŒ…å«markdownå†…å®¹çš„å˜é‡ï¼Œä¼ å…¥å…³è”çš„å›¾ç‰‡æ–‡ä»¶ä¿¡æ¯
            if key == "dialog_files_content" and dialog_image_files:
                logger.info(f"å¤„ç†markdownå†…å®¹å˜é‡ï¼Œå…³è”å›¾ç‰‡æ–‡ä»¶: {len(dialog_image_files)} ä¸ª")
                processed_value, resources = self._extract_and_download_resources(
                    value, related_image_files=dialog_image_files
                )
            else:
                # ç»Ÿä¸€ä½¿ç”¨ _extract_and_download_resources å¤„ç†å…¶ä»–å˜é‡
                processed_value, resources = self._extract_and_download_resources(value)

            # åˆå¹¶èµ„æºä¿¡æ¯
            all_resources["images"].extend(resources.get("images", []))
            all_resources["excel_files"].extend(resources.get("excel_files", []))
            all_resources["csv_files"].extend(resources.get("csv_files", []))
            all_resources["markdown_tables"].extend(resources.get("markdown_tables", []))

            template_def.append(["{{" + key + "}}", processed_value])

        # å°†å˜é‡å’Œèµ„æºä¿¡æ¯ä¸€èµ·æ¸²æŸ“åˆ°docxæ¨¡æ¿æ–‡ä»¶
        output_doc = doc_parse.render(template_def, all_resources)
        output_content = io.BytesIO()
        output_doc.save(output_content)
        output_content.seek(0)

        # minioçš„ä¸´æ—¶ç›®å½•
        tmp_object_name = f"workflow/report/{uuid4().hex}/{self._file_name}"
        # upload file to minio
        self._minio_client.upload_tmp(tmp_object_name, output_content.read())
        # get share link
        file_share_url = self._minio_client.get_share_link(tmp_object_name, self._minio_client.tmp_bucket)

        self.callback_manager.on_output_msg(
            OutputMsgData(
                **{
                    "unique_id": unique_id,
                    "node_id": self.id,
                    "name": self.name,
                    "msg": "",
                    "files": [{"path": file_share_url, "name": self._file_name}],
                    "output_key": "",
                }
            )
        )


def test_report_node_scenario():
    """
    æµ‹è¯•ç”¨æˆ·åœºæ™¯ï¼šå¤„ç†åµŒå…¥åœ¨æ–‡æœ¬ä¸­çš„å›¾ç‰‡å’Œè¡¨æ ¼è·¯å¾„

    æµ‹è¯•ç”¨ä¾‹ï¼š
    1. å›¾ç‰‡åµŒå…¥æ–‡æœ¬ï¼šasdasd/ada/ada.jpgdasda
    2. Excelæ–‡ä»¶åµŒå…¥æ–‡æœ¬ï¼šæŠ¥å‘Šæ•°æ®file/data.xlsxè¯·æŸ¥çœ‹
    3. Markdownè¡¨æ ¼åœ¨æ–‡æœ¬ä¸­
    """
    print("ğŸ¯ æµ‹è¯•ReportNodeåœºæ™¯å¤„ç†")

    # åˆ›å»ºæµ‹è¯•å®ä¾‹ï¼ˆæ¨¡æ‹Ÿå¿…è¦çš„å‚æ•°ï¼‰

    # åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„æµ‹è¯•ç±»æ¥æµ‹è¯•_extract_and_download_resourcesæ–¹æ³•
    class TestReportNode:
        def __init__(self):
            pass

        def _is_valid_url(self, url: str) -> bool:
            try:
                from urllib.parse import urlparse

                result = urlparse(url)
                return all([result.scheme, result.netloc])
            except ValueError:
                return False

        def _download_file(self, url: str):
            # æ¨¡æ‹Ÿä¸‹è½½å¤±è´¥ï¼ˆæµ‹è¯•ç”¨ï¼‰
            logger.info(f"æ¨¡æ‹Ÿä¸‹è½½: {url}")
            return "", False

        def _extract_and_download_resources(self, value: str):
            # å°†åŸæ¥çš„æ–¹æ³•å¤åˆ¶è¿‡æ¥è¿›è¡Œæµ‹è¯•
            if not isinstance(value, str):
                return str(value), {}

            # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
            patterns = {
                "markdown_image": r"!\[([^\]]*)\]\(([^)]+\.(?:png|jpg|jpeg|bmp)(?:\?[^)]*)?)\)",
                "local_image": r"([^\s]*\.(?:png|jpg|jpeg|bmp))",
                "minio_image": r"((?:minio://|/bisheng/|/tmp-dir/)[^\s]*\.(?:png|jpg|jpeg|bmp))",
                "http_image": r"(https?://[^\s\u4e00-\u9fff]*\.(?:png|jpg|jpeg|bmp)(?:\?[^\s\u4e00-\u9fff]*)?)",
                "excel_file": r"([^\s]*\.(?:xls|xlsx)(?:\?[^\s]*)?)",
                "markdown_table": r"(\|[^|\n]*\|(?:\n\|[^|\n]*\|)*)",
            }

            processed_value = value
            resources = {"images": [], "excel_files": [], "markdown_tables": []}

            processed_paths = set()

            # å¤„ç†å›¾ç‰‡è·¯å¾„
            import re

            local_images = re.findall(patterns["local_image"], processed_value, re.IGNORECASE)
            for img_path in local_images:
                if (
                    img_path not in processed_paths
                    and ("/" in img_path or "\\" in img_path)
                    and not self._is_valid_url(img_path)
                ):
                    processed_paths.add(img_path)
                    placeholder = f"__IMAGE_PLACEHOLDER_{self._get_unique_placeholder_id()}__"
                    resources["images"].append(
                        {
                            "original_path": img_path,
                            "local_path": img_path,
                            "alt_text": "å›¾ç‰‡",
                            "placeholder": placeholder,
                            "type": "local",
                            "original_text": img_path,
                        }
                    )
                    processed_value = processed_value.replace(img_path, placeholder)

            # å¤„ç†Excelæ–‡ä»¶
            excel_files = re.findall(patterns["excel_file"], processed_value, re.IGNORECASE)
            for excel_path in excel_files:
                if excel_path not in processed_paths:
                    processed_paths.add(excel_path)
                    placeholder = f"__EXCEL_PLACEHOLDER_{self._get_unique_placeholder_id()}__"
                    resources["excel_files"].append(
                        {
                            "original_path": excel_path,
                            "placeholder": placeholder,
                            "type": "local",
                            "original_text": excel_path,
                        }
                    )
                    processed_value = processed_value.replace(excel_path, placeholder)

            # å¤„ç†Markdownè¡¨æ ¼
            markdown_tables = re.findall(patterns["markdown_table"], processed_value, re.MULTILINE)
            for table_content in markdown_tables:
                placeholder = f"__TABLE_PLACEHOLDER_{self._get_unique_placeholder_id()}__"
                resources["markdown_tables"].append(
                    {
                        "content": table_content,
                        "placeholder": placeholder,
                        "type": "markdown",
                        "original_text": table_content,
                    }
                )
                processed_value = processed_value.replace(table_content, placeholder)

            return processed_value, resources

    node = TestReportNode()

    # æµ‹è¯•åœºæ™¯1ï¼šå›¾ç‰‡åµŒå…¥æ–‡æœ¬
    test_value_1 = "è¿™æ˜¯æŠ¥å‘Šå‰è¨€asdasd/ada/ada.jpgdasdaè¿™æ˜¯ç»“å°¾"
    print(f"\nğŸ“ åŸå§‹æ–‡æœ¬: {test_value_1}")

    processed_value, resources = node._extract_and_download_resources(test_value_1)
    print(f"âœ… å¤„ç†åæ–‡æœ¬: {processed_value}")
    print(f"ğŸ–¼ï¸ è¯†åˆ«åˆ°çš„å›¾ç‰‡: {[img['original_path'] for img in resources['images']]}")

    # æµ‹è¯•åœºæ™¯2ï¼šExcelæ–‡ä»¶åµŒå…¥æ–‡æœ¬
    test_value_2 = "æŠ¥å‘Šæ•°æ®è¯·å‚è€ƒfile/data.xlsxæ–‡ä»¶è¯¦æƒ…"
    print(f"\nğŸ“ åŸå§‹æ–‡æœ¬: {test_value_2}")

    processed_value_2, resources_2 = node._extract_and_download_resources(test_value_2)
    print(f"âœ… å¤„ç†åæ–‡æœ¬: {processed_value_2}")
    print(f"ğŸ“Š è¯†åˆ«åˆ°çš„Excel: {[excel['original_path'] for excel in resources_2['excel_files']]}")

    # æµ‹è¯•åœºæ™¯3ï¼šå¤šç§èµ„æºæ··åˆï¼ˆåŒ…æ‹¬MinIOè·¯å¾„ï¼‰
    test_value_3 = """
    æŠ¥å‘Šæ‘˜è¦ï¼šå›¾ç‰‡è·¯å¾„/path/image.pngå’Œæ•°æ®è¡¨data/report.xlsx
    
    MinIOå›¾ç‰‡ï¼š/bisheng/knowledge/images/123/test.jpg
    ä¸´æ—¶å›¾ç‰‡ï¼š/tmp-dir/temp/demo.png
    MinIO Excelï¼š/bisheng/reports/data.xlsx
    
    | é¡¹ç›® | æ•°å€¼ |
    |------|------|
    | A    | 100  |
    | B    | 200  |
    
    è¿˜æœ‰ç½‘ç»œå›¾ç‰‡https://example.com/chart.jpg
    """
    print(f"\nğŸ“ åŸå§‹æ–‡æœ¬: {test_value_3}")

    processed_value_3, resources_3 = node._extract_and_download_resources(test_value_3)
    print(f"âœ… å¤„ç†åæ–‡æœ¬: {processed_value_3}")
    print(f"ğŸ–¼ï¸ è¯†åˆ«åˆ°çš„å›¾ç‰‡: {len(resources_3['images'])} ä¸ª")
    print(f"ğŸ“Š è¯†åˆ«åˆ°çš„Excel: {len(resources_3['excel_files'])} ä¸ª")
    print(f"ğŸ“‹ è¯†åˆ«åˆ°çš„è¡¨æ ¼: {len(resources_3['markdown_tables'])} ä¸ª")

    # æ˜¾ç¤ºè¯†åˆ«åˆ°çš„èµ„æºè¯¦æƒ…
    for i, img in enumerate(resources_3["images"]):
        print(f"  å›¾ç‰‡{i+1}: {img['original_path']} -> {img['type']}")
    for i, excel in enumerate(resources_3["excel_files"]):
        print(f"  Excel{i+1}: {excel['original_path']} -> {excel['type']}")

    # æµ‹è¯•åœºæ™¯4ï¼šå¤æ‚æ··åˆå†…å®¹ï¼ˆä¸€æ®µè¯ä¸­å¤šç§èµ„æºï¼‰
    test_value_4 = """
    ç»¼åˆåˆ†ææŠ¥å‘Šï¼šé¦–å…ˆæŸ¥çœ‹/bisheng/charts/overview.pngæ¦‚è§ˆå›¾ï¼Œ
    ç„¶åå‚è€ƒ/tmp-dir/data/sales.xlsxé”€å”®æ•°æ®ï¼Œæœ€åæ˜¯ç»Ÿè®¡è¡¨æ ¼ï¼š
    
    | å­£åº¦ | é”€å”®é¢ | å¢é•¿ç‡ |
    |------|-------|--------|
    | Q1   | 100ä¸‡ | 10%    |
    | Q2   | 120ä¸‡ | 20%    |
    
    è¡¥å……å›¾è¡¨https://example.com/trends.jpgæ˜¾ç¤ºè¶‹åŠ¿ï¼Œ
    è¯¦ç»†æ•°æ®è§report.xlsxæ–‡ä»¶åˆ†æã€‚
    """
    print("\nğŸ“ æµ‹è¯•åœºæ™¯4 - å¤æ‚æ··åˆå†…å®¹:")
    print(f"åŸå§‹æ–‡æœ¬: {test_value_4}")

    processed_value_4, resources_4 = node._extract_and_download_resources(test_value_4)
    print(f"âœ… å¤„ç†åæ–‡æœ¬: {processed_value_4}")
    print("ğŸ” èµ„æºç»Ÿè®¡:")
    print(f"  - å›¾ç‰‡: {len(resources_4['images'])} ä¸ª")
    print(f"  - Excel: {len(resources_4['excel_files'])} ä¸ª")
    print(f"  - è¡¨æ ¼: {len(resources_4['markdown_tables'])} ä¸ª")

    # æ˜¾ç¤ºå¤„ç†åçš„å ä½ç¬¦åˆ†å¸ƒ
    print("\nğŸ¯ å ä½ç¬¦åˆ†å¸ƒ:")
    for i, img in enumerate(resources_4["images"]):
        print(f"  {img['placeholder']} â† {img['original_path']}")
    for i, excel in enumerate(resources_4["excel_files"]):
        print(f"  {excel['placeholder']} â† {excel['original_path']}")
    for i, table in enumerate(resources_4["markdown_tables"]):
        print(f"  {table['placeholder']} â† Markdownè¡¨æ ¼")

    return True


if __name__ == "__main__":
    test_report_node_scenario()
