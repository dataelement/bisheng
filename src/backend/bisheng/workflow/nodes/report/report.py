import io
import re
import os
import tempfile
import requests
from urllib.parse import urlparse, unquote
from pathlib import Path
from uuid import uuid4
from loguru import logger
from typing import Dict, List, Tuple, Any

from bisheng.utils.minio_client import MinioClient
from bisheng.utils.docx_temp import DocxTemplateRender
from bisheng.workflow.callback.event import OutputMsgData
from bisheng.workflow.nodes.base import BaseNode


class ReportNode(BaseNode):

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._report_info = self.node_params['report_info']
        self._version_key = self._report_info['version_key'].split('_')[0]
        self._object_name = f"workflow/report/{self._version_key}.docx"
        self._file_name = self._report_info['file_name'] if self._report_info['file_name'] else 'tmp_report.docx'
        if not self._file_name.endswith('.docx'):
            self._file_name += '.docx'
        self._minio_client = MinioClient()
        # å­˜å‚¨ä¸‹è½½çš„æ–‡ä»¶ä¿¡æ¯ï¼Œç”¨äºåç»­æ’å…¥æ–‡æ¡£
        self._downloaded_files: Dict[str, str] = {}

    def _is_valid_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„URL"""
        try:
            result = urlparse(url)
            return all([result.scheme, result.netloc])
        except ValueError:
            return False

    def _download_file(self, url: str) -> Tuple[str, bool]:
        """
        ä¸‹è½½æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        
        Args:
            url: æ–‡ä»¶URL
            
        Returns:
            tuple: (æœ¬åœ°æ–‡ä»¶è·¯å¾„, æ˜¯å¦ä¸‹è½½æˆåŠŸ)
        """
        try:
            # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—®
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=30, verify=False)
            response.raise_for_status()
            
            # è·å–æ–‡ä»¶å
            content_disposition = response.headers.get('Content-Disposition', '')
            filename = ''
            if content_disposition:
                filename = unquote(content_disposition).split('filename=')[-1].strip("\"'")
            if not filename:
                filename = unquote(urlparse(url).path.split('/')[-1])
            if not filename:
                # æ ¹æ®Content-Typeæ¨æ–­æ‰©å±•å
                content_type = response.headers.get('Content-Type', '').lower()
                if 'image/png' in content_type:
                    filename = f"{uuid4().hex}.png"
                elif 'image/jpeg' in content_type or 'image/jpg' in content_type:
                    filename = f"{uuid4().hex}.jpg"
                elif 'image/bmp' in content_type:
                    filename = f"{uuid4().hex}.bmp"
                elif 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet' in content_type:
                    filename = f"{uuid4().hex}.xlsx"
                elif 'application/vnd.ms-excel' in content_type:
                    filename = f"{uuid4().hex}.xls"
                else:
                    filename = f"{uuid4().hex}.dat"
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_dir = tempfile.gettempdir()
            temp_file = os.path.join(temp_dir, filename)
            
            with open(temp_file, 'wb') as f:
                f.write(response.content)
            
            logger.info(f"æˆåŠŸä¸‹è½½æ–‡ä»¶: {url} -> {temp_file}")
            return temp_file, True
            
        except Exception as e:
            logger.error(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {url}, é”™è¯¯: {str(e)}")
            return "", False

    def _download_minio_file(self, minio_path: str) -> Tuple[str, bool]:
        """
        ä»MinIOä¸‹è½½æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        
        Args:
            minio_path: MinIOæ–‡ä»¶è·¯å¾„
            
        Returns:
            tuple: (æœ¬åœ°æ–‡ä»¶è·¯å¾„, æ˜¯å¦ä¸‹è½½æˆåŠŸ)
        """
        try:
            # è§£æMinIOè·¯å¾„
            bucket_name = None
            object_name = None
            
            if minio_path.startswith('minio://'):
                # æ ¼å¼: minio://bucket/object/name
                parts = minio_path[8:].split('/', 1)
                if len(parts) == 2:
                    bucket_name, object_name = parts
                else:
                    object_name = parts[0]
                    bucket_name = self._minio_client.bucket  # é»˜è®¤bucket
            elif minio_path.startswith('/bisheng/'):
                # æ ¼å¼: /bisheng/object/name
                bucket_name = self._minio_client.bucket
                object_name = minio_path[9:]  # ç§»é™¤ '/bisheng/'
            elif minio_path.startswith('/tmp-dir/'):
                # æ ¼å¼: /tmp-dir/object/name
                bucket_name = self._minio_client.tmp_bucket
                object_name = minio_path[9:]  # ç§»é™¤ '/tmp-dir/'
            else:
                # å°è¯•ä½œä¸ºå®Œæ•´URLå¤„ç†
                if self._is_valid_url(minio_path):
                    return self._download_file(minio_path)
                else:
                    logger.error(f"æ— æ³•è§£æMinIOè·¯å¾„: {minio_path}")
                    return "", False
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not self._minio_client.object_exists(bucket_name, object_name):
                logger.error(f"MinIOæ–‡ä»¶ä¸å­˜åœ¨: {bucket_name}/{object_name}")
                return "", False
            
            # ä¸‹è½½æ–‡ä»¶å†…å®¹
            file_content = self._minio_client.get_object(bucket_name, object_name)
            
            # ç”Ÿæˆä¸´æ—¶æ–‡ä»¶å
            file_ext = os.path.splitext(object_name)[1] or '.dat'
            filename = f"{uuid4().hex}{file_ext}"
            temp_dir = tempfile.gettempdir()
            temp_file = os.path.join(temp_dir, filename)
            
            # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            with open(temp_file, 'wb') as f:
                f.write(file_content)
            
            logger.info(f"æˆåŠŸä»MinIOä¸‹è½½æ–‡ä»¶: {minio_path} -> {temp_file}")
            return temp_file, True
            
        except Exception as e:
            logger.error(f"ä»MinIOä¸‹è½½æ–‡ä»¶å¤±è´¥: {minio_path}, é”™è¯¯: {str(e)}")
            return "", False

    def _extract_and_download_resources(self, value: str) -> Tuple[str, Dict[str, Any]]:
        """
        ä»å˜é‡å€¼ä¸­æå–å¹¶ä¸‹è½½èµ„æºæ–‡ä»¶
        
        Args:
            value: åŸå§‹å˜é‡å€¼
            
        Returns:
            tuple: (å¤„ç†åçš„å˜é‡å€¼, èµ„æºä¿¡æ¯å­—å…¸)
        """
        if not isinstance(value, str):
            return str(value), {}
        
        # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        patterns = {
            # å›¾ç‰‡æ¨¡å¼ - æŒ‰ä¼˜å…ˆçº§æ’åº
            'markdown_image': r'!\[([^\]]*)\]\(([^)]+\.(?:png|jpg|jpeg|bmp))\)',  # Markdownæ ¼å¼å›¾ç‰‡
            'local_image': r'([^\s]*\.(?:png|jpg|jpeg|bmp))',  # æœ¬åœ°è·¯å¾„å›¾ç‰‡ï¼ˆåµŒå…¥æ–‡æœ¬ä¸­ï¼‰
            'minio_image': r'((?:minio://|/bisheng/|/tmp-dir/)[^\s]*\.(?:png|jpg|jpeg|bmp))',  # MinIOè·¯å¾„å›¾ç‰‡
            'http_image': r'(https?://[^\s]*\.(?:png|jpg|jpeg|bmp))',  # HTTP/HTTPSå›¾ç‰‡
            
            # è¡¨æ ¼æ¨¡å¼
            'excel_file': r'([^\s]*\.(?:xls|xlsx))',  # Excelæ–‡ä»¶ï¼ˆåµŒå…¥æ–‡æœ¬ä¸­ï¼‰
            'markdown_table': r'(\|[^|\n]*\|(?:\n\|[^|\n]*\|)*)',  # Markdownè¡¨æ ¼
        }
        
        processed_value = value
        resources = {
            'images': [],
            'excel_files': [],
            'markdown_tables': []
        }
        
        # ç”¨äºè·Ÿè¸ªå·²å¤„ç†çš„è·¯å¾„ï¼Œé¿å…é‡å¤
        processed_paths = set()
        
        # 1. å¤„ç†å›¾ç‰‡ - æŒ‰ä¼˜å…ˆçº§æ’åº
        # 1.1 Markdownæ ¼å¼å›¾ç‰‡ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        markdown_images = re.findall(patterns['markdown_image'], processed_value, re.IGNORECASE)
        for alt_text, img_path in markdown_images:
            if img_path not in processed_paths:
                processed_paths.add(img_path)
                
                if not self._is_valid_url(img_path):  # æœ¬åœ°è·¯å¾„
                    if os.path.exists(img_path):
                        # æœ¬åœ°æ–‡ä»¶å­˜åœ¨ï¼Œè®°å½•åˆ°èµ„æºåˆ—è¡¨
                        placeholder = f"__IMAGE_PLACEHOLDER_{len(resources['images'])}__"
                        resources['images'].append({
                            'original_path': img_path,
                            'local_path': img_path,
                            'alt_text': alt_text,
                            'placeholder': placeholder,
                            'type': 'local',
                            'original_text': f"![{alt_text}]({img_path})"
                        })
                        # åœ¨æ–‡æ¡£ä¸­ç”¨å ä½ç¬¦æ›¿æ¢
                        processed_value = processed_value.replace(f"![{alt_text}]({img_path})", placeholder)
                        logger.info(f"è¯†åˆ«åˆ°æœ¬åœ°Markdownå›¾ç‰‡: {img_path}")
                    else:
                        logger.warning(f"æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
                else:
                    # ç½‘ç»œå›¾ç‰‡ï¼Œä¸‹è½½å¤„ç†
                    local_path, success = self._download_file(img_path)
                    placeholder = f"__IMAGE_PLACEHOLDER_{len(resources['images'])}__"
                    
                    if success:
                        resources['images'].append({
                            'original_path': img_path,
                            'local_path': local_path,
                            'alt_text': alt_text,
                            'placeholder': placeholder,
                            'type': 'downloaded',
                            'original_text': f"![{alt_text}]({img_path})"
                        })
                        logger.info(f"ç½‘ç»œMarkdownå›¾ç‰‡ä¸‹è½½æˆåŠŸ: {img_path} -> {local_path}")
                    else:
                        resources['images'].append({
                            'original_path': img_path,
                            'local_path': img_path,
                            'alt_text': alt_text,
                            'placeholder': placeholder,
                            'type': 'failed',
                            'original_text': f"![{alt_text}]({img_path})"
                        })
                        logger.warning(f"ç½‘ç»œMarkdownå›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_path}")
                    
                    processed_value = processed_value.replace(f"![{alt_text}]({img_path})", placeholder)
        
        # 1.2 MinIOè·¯å¾„å›¾ç‰‡ - ä¸‹è½½åˆ°æœ¬åœ°
        minio_images = re.findall(patterns['minio_image'], processed_value, re.IGNORECASE)
        for img_path in minio_images:
            if img_path not in processed_paths:
                processed_paths.add(img_path)
                # ä¸‹è½½MinIOå›¾ç‰‡åˆ°æœ¬åœ°
                local_path, success = self._download_minio_file(img_path)
                placeholder = f"__IMAGE_PLACEHOLDER_{len(resources['images'])}__"
                
                if success:
                    resources['images'].append({
                        'original_path': img_path,
                        'local_path': local_path,
                        'alt_text': 'å›¾ç‰‡',
                        'placeholder': placeholder,
                        'type': 'downloaded',
                        'original_text': img_path
                    })
                    logger.info(f"MinIOå›¾ç‰‡ä¸‹è½½æˆåŠŸ: {img_path} -> {local_path}")
                else:
                    resources['images'].append({
                        'original_path': img_path,
                        'local_path': img_path,
                        'alt_text': 'å›¾ç‰‡',
                        'placeholder': placeholder,
                        'type': 'failed',
                        'original_text': img_path
                    })
                    logger.warning(f"MinIOå›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_path}")
                
                processed_value = processed_value.replace(img_path, placeholder)
        
        # 1.3 HTTP/HTTPSå›¾ç‰‡é“¾æ¥
        http_images = re.findall(patterns['http_image'], processed_value, re.IGNORECASE)
        for img_url in http_images:
            if img_url not in processed_paths:
                processed_paths.add(img_url)
                local_path, success = self._download_file(img_url)
                placeholder = f"__IMAGE_PLACEHOLDER_{len(resources['images'])}__"
                
                if success:
                    resources['images'].append({
                        'original_path': img_url,
                        'local_path': local_path,
                        'alt_text': 'å›¾ç‰‡',
                        'placeholder': placeholder,
                        'type': 'downloaded',
                        'original_text': img_url
                    })
                    logger.info(f"ç½‘ç»œå›¾ç‰‡ä¸‹è½½æˆåŠŸ: {img_url} -> {local_path}")
                else:
                    resources['images'].append({
                        'original_path': img_url,
                        'local_path': img_url,
                        'alt_text': 'å›¾ç‰‡',
                        'placeholder': placeholder,
                        'type': 'failed',
                        'original_text': img_url
                    })
                    logger.warning(f"ç½‘ç»œå›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_url}")
                
                processed_value = processed_value.replace(img_url, placeholder)
        
        # 1.4 æœ¬åœ°è·¯å¾„å›¾ç‰‡ï¼ˆæœ€åå¤„ç†ï¼Œé¿å…è¯¯åŒ¹é…ï¼‰
        local_images = re.findall(patterns['local_image'], processed_value, re.IGNORECASE)
        for img_path in local_images:
            # è¿‡æ»¤æ‰å·²å¤„ç†çš„è·¯å¾„å’Œæ˜æ˜¾ä¸æ˜¯è·¯å¾„çš„æ–‡æœ¬
            if (img_path not in processed_paths and 
                ('/' in img_path or '\\' in img_path) and  # å¿…é¡»åŒ…å«è·¯å¾„åˆ†éš”ç¬¦
                not self._is_valid_url(img_path) and 
                not img_path.startswith('minio://') and
                not img_path.startswith('/bisheng/') and
                not img_path.startswith('/tmp-dir/')):
                
                processed_paths.add(img_path)
                if os.path.exists(img_path):
                    placeholder = f"__IMAGE_PLACEHOLDER_{len(resources['images'])}__"
                    resources['images'].append({
                        'original_path': img_path,
                        'local_path': img_path,
                        'alt_text': 'å›¾ç‰‡',
                        'placeholder': placeholder,
                        'type': 'local',
                        'original_text': img_path
                    })
                    processed_value = processed_value.replace(img_path, placeholder)
                    logger.info(f"è¯†åˆ«åˆ°æœ¬åœ°å›¾ç‰‡: {img_path}")
                else:
                    logger.warning(f"æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {img_path}")
        
        # 2. å¤„ç†Excelè¡¨æ ¼æ–‡ä»¶
        excel_files = re.findall(patterns['excel_file'], processed_value, re.IGNORECASE)
        for excel_path in excel_files:
            if excel_path not in processed_paths:
                processed_paths.add(excel_path)
                placeholder = f"__EXCEL_PLACEHOLDER_{len(resources['excel_files'])}__"
                
                if self._is_valid_url(excel_path):
                    # ç½‘ç»œExcelæ–‡ä»¶
                    local_path, success = self._download_file(excel_path)
                    if success:
                        resources['excel_files'].append({
                            'original_path': excel_path,
                            'local_path': local_path,
                            'placeholder': placeholder,
                            'type': 'downloaded',
                            'original_text': excel_path
                        })
                        logger.info(f"Excelæ–‡ä»¶ä¸‹è½½æˆåŠŸ: {excel_path} -> {local_path}")
                    else:
                        resources['excel_files'].append({
                            'original_path': excel_path,
                            'local_path': excel_path,
                            'placeholder': placeholder,
                            'type': 'failed',
                            'original_text': excel_path
                        })
                        logger.warning(f"Excelæ–‡ä»¶ä¸‹è½½å¤±è´¥: {excel_path}")
                elif (excel_path.startswith('/bisheng/') or 
                      excel_path.startswith('/tmp-dir/') or 
                      excel_path.startswith('minio://')):
                    # MinIO Excelæ–‡ä»¶
                    local_path, success = self._download_minio_file(excel_path)
                    if success:
                        resources['excel_files'].append({
                            'original_path': excel_path,
                            'local_path': local_path,
                            'placeholder': placeholder,
                            'type': 'downloaded',
                            'original_text': excel_path
                        })
                        logger.info(f"MinIO Excelæ–‡ä»¶ä¸‹è½½æˆåŠŸ: {excel_path} -> {local_path}")
                    else:
                        resources['excel_files'].append({
                            'original_path': excel_path,
                            'local_path': excel_path,
                            'placeholder': placeholder,
                            'type': 'failed',
                            'original_text': excel_path
                        })
                        logger.warning(f"MinIO Excelæ–‡ä»¶ä¸‹è½½å¤±è´¥: {excel_path}")
                else:
                    # æœ¬åœ°Excelæ–‡ä»¶
                    if os.path.exists(excel_path):
                        resources['excel_files'].append({
                            'original_path': excel_path,
                            'local_path': excel_path,
                            'placeholder': placeholder,
                            'type': 'local',
                            'original_text': excel_path
                        })
                        logger.info(f"è¯†åˆ«åˆ°æœ¬åœ°Excelæ–‡ä»¶: {excel_path}")
                    else:
                        resources['excel_files'].append({
                            'original_path': excel_path,
                            'local_path': excel_path,
                            'placeholder': placeholder,
                            'type': 'missing',
                            'original_text': excel_path
                        })
                        logger.warning(f"æœ¬åœ°Excelæ–‡ä»¶ä¸å­˜åœ¨: {excel_path}")
                
                processed_value = processed_value.replace(excel_path, placeholder)
        
        # 3. å¤„ç†Markdownè¡¨æ ¼ï¼ˆä¿æŒä¸å˜ï¼‰
        markdown_tables = re.findall(patterns['markdown_table'], processed_value, re.MULTILINE)
        for table_content in markdown_tables:
            placeholder = f"__TABLE_PLACEHOLDER_{len(resources['markdown_tables'])}__"
            resources['markdown_tables'].append({
                'content': table_content,
                'placeholder': placeholder,
                'type': 'markdown',
                'original_text': table_content
            })
            processed_value = processed_value.replace(table_content, placeholder)
            logger.info(f"è¯†åˆ«åˆ°Markdownè¡¨æ ¼ï¼Œè¡Œæ•°: {table_content.count('|')}")
        
        return processed_value, resources

    def _run(self, unique_id: str):
        # ä¸‹è½½æŠ¥å‘Šæ¨¡æ¿æ–‡ä»¶
        if not self._minio_client.object_exists(self._minio_client.bucket, self._object_name):
            raise Exception(f"{self.name}èŠ‚ç‚¹æ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆç¼–è¾‘å¯¹åº”çš„æŠ¥å‘Šæ¨¡æ¿")
        file_content = self._minio_client.get_object(self._minio_client.bucket, self._object_name)
        doc_parse = DocxTemplateRender(file_content=io.BytesIO(file_content))
        
        # è·å–æ‰€æœ‰çš„èŠ‚ç‚¹å˜é‡
        all_variables = self.graph_state.get_all_variables()
        template_def = []
        all_resources = {
            'images': [],
            'excel_files': [],
            'markdown_tables': []
        }
        
        # å¤„ç†æ¯ä¸ªå˜é‡å€¼
        for key, value in all_variables.items():
            # æå–å¹¶ä¸‹è½½èµ„æºæ–‡ä»¶
            processed_value, resources = self._extract_and_download_resources(str(value))
            
            # åˆå¹¶èµ„æºä¿¡æ¯
            all_resources['images'].extend(resources.get('images', []))
            all_resources['excel_files'].extend(resources.get('excel_files', []))
            all_resources['markdown_tables'].extend(resources.get('markdown_tables', []))
            
            template_def.append(["{{" + key + "}}", processed_value])

        # å°†å˜é‡å’Œèµ„æºä¿¡æ¯ä¸€èµ·æ¸²æŸ“åˆ°docxæ¨¡æ¿æ–‡ä»¶
        output_doc = doc_parse.render(template_def, all_resources)
        output_content = io.BytesIO()
        output_doc.save(output_content)
        output_content.seek(0)

        # minioçš„ä¸´æ—¶ç›®å½•
        tmp_object_name = f"workflow/report/{uuid4().hex}/{self._file_name}"
        # upload file to minio
        self._minio_client.upload_tmp(tmp_object_name, output_content.read())
        # get share link
        file_share_url = self._minio_client.get_share_link(tmp_object_name, self._minio_client.tmp_bucket)

        self.callback_manager.on_output_msg(OutputMsgData(**{
            'unique_id': unique_id,
            'node_id': self.id,
            'msg': "",
            'files': [{'path': file_share_url, 'name': self._file_name}],
            'output_key': '',
        }))


def test_report_node_scenario():
    """
    æµ‹è¯•ç”¨æˆ·åœºæ™¯ï¼šå¤„ç†åµŒå…¥åœ¨æ–‡æœ¬ä¸­çš„å›¾ç‰‡å’Œè¡¨æ ¼è·¯å¾„
    
    æµ‹è¯•ç”¨ä¾‹ï¼š
    1. å›¾ç‰‡åµŒå…¥æ–‡æœ¬ï¼šasdasd/ada/ada.jpgdasda
    2. Excelæ–‡ä»¶åµŒå…¥æ–‡æœ¬ï¼šæŠ¥å‘Šæ•°æ®file/data.xlsxè¯·æŸ¥çœ‹
    3. Markdownè¡¨æ ¼åœ¨æ–‡æœ¬ä¸­
    """
    print("ğŸ¯ æµ‹è¯•ReportNodeåœºæ™¯å¤„ç†")
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹ï¼ˆæ¨¡æ‹Ÿå¿…è¦çš„å‚æ•°ï¼‰
    test_params = {
        'report_info': {
            'version_key': 'test_123',
            'file_name': 'test_report.docx'
        }
    }
    
    # åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„æµ‹è¯•ç±»æ¥æµ‹è¯•_extract_and_download_resourcesæ–¹æ³•
    class TestReportNode:
        def __init__(self):
            pass
            
        def _is_valid_url(self, url: str) -> bool:
            try:
                from urllib.parse import urlparse
                result = urlparse(url)
                return all([result.scheme, result.netloc])
            except ValueError:
                return False
        
        def _download_file(self, url: str):
            # æ¨¡æ‹Ÿä¸‹è½½å¤±è´¥ï¼ˆæµ‹è¯•ç”¨ï¼‰
            logger.info(f"æ¨¡æ‹Ÿä¸‹è½½: {url}")
            return "", False
        
        def _extract_and_download_resources(self, value: str):
            # å°†åŸæ¥çš„æ–¹æ³•å¤åˆ¶è¿‡æ¥è¿›è¡Œæµ‹è¯•
            if not isinstance(value, str):
                return str(value), {}
            
            # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
            patterns = {
                'markdown_image': r'!\[([^\]]*)\]\(([^)]+\.(?:png|jpg|jpeg|bmp))\)',
                'local_image': r'([^\s]*\.(?:png|jpg|jpeg|bmp))',
                'minio_image': r'((?:minio://|/bisheng/|/tmp-dir/)[^\s]*\.(?:png|jpg|jpeg|bmp))',
                'http_image': r'(https?://[^\s]*\.(?:png|jpg|jpeg|bmp))',
                'excel_file': r'([^\s]*\.(?:xls|xlsx))',
                'markdown_table': r'(\|[^|\n]*\|(?:\n\|[^|\n]*\|)*)',
            }
            
            processed_value = value
            resources = {
                'images': [],
                'excel_files': [],
                'markdown_tables': []
            }
            
            processed_paths = set()
            
            # å¤„ç†å›¾ç‰‡è·¯å¾„
            import re
            local_images = re.findall(patterns['local_image'], processed_value, re.IGNORECASE)
            for img_path in local_images:
                if (img_path not in processed_paths and 
                    ('/' in img_path or '\\' in img_path) and
                    not self._is_valid_url(img_path)):
                    
                    processed_paths.add(img_path)
                    placeholder = f"__IMAGE_PLACEHOLDER_{len(resources['images'])}__"
                    resources['images'].append({
                        'original_path': img_path,
                        'local_path': img_path,
                        'alt_text': 'å›¾ç‰‡',
                        'placeholder': placeholder,
                        'type': 'local',
                        'original_text': img_path
                    })
                    processed_value = processed_value.replace(img_path, placeholder)
            
            # å¤„ç†Excelæ–‡ä»¶
            excel_files = re.findall(patterns['excel_file'], processed_value, re.IGNORECASE)
            for excel_path in excel_files:
                if excel_path not in processed_paths:
                    processed_paths.add(excel_path)
                    placeholder = f"__EXCEL_PLACEHOLDER_{len(resources['excel_files'])}__"
                    resources['excel_files'].append({
                        'original_path': excel_path,
                        'placeholder': placeholder,
                        'type': 'local',
                        'original_text': excel_path
                    })
                    processed_value = processed_value.replace(excel_path, placeholder)
            
            # å¤„ç†Markdownè¡¨æ ¼
            markdown_tables = re.findall(patterns['markdown_table'], processed_value, re.MULTILINE)
            for table_content in markdown_tables:
                placeholder = f"__TABLE_PLACEHOLDER_{len(resources['markdown_tables'])}__"
                resources['markdown_tables'].append({
                    'content': table_content,
                    'placeholder': placeholder,
                    'type': 'markdown',
                    'original_text': table_content
                })
                processed_value = processed_value.replace(table_content, placeholder)
            
            return processed_value, resources
    
    node = TestReportNode()
    
    # æµ‹è¯•åœºæ™¯1ï¼šå›¾ç‰‡åµŒå…¥æ–‡æœ¬
    test_value_1 = "è¿™æ˜¯æŠ¥å‘Šå‰è¨€asdasd/ada/ada.jpgdasdaè¿™æ˜¯ç»“å°¾"
    print(f"\nğŸ“ åŸå§‹æ–‡æœ¬: {test_value_1}")
    
    processed_value, resources = node._extract_and_download_resources(test_value_1)
    print(f"âœ… å¤„ç†åæ–‡æœ¬: {processed_value}")
    print(f"ğŸ–¼ï¸ è¯†åˆ«åˆ°çš„å›¾ç‰‡: {[img['original_path'] for img in resources['images']]}")
    
    # æµ‹è¯•åœºæ™¯2ï¼šExcelæ–‡ä»¶åµŒå…¥æ–‡æœ¬  
    test_value_2 = "æŠ¥å‘Šæ•°æ®è¯·å‚è€ƒfile/data.xlsxæ–‡ä»¶è¯¦æƒ…"
    print(f"\nğŸ“ åŸå§‹æ–‡æœ¬: {test_value_2}")
    
    processed_value_2, resources_2 = node._extract_and_download_resources(test_value_2)
    print(f"âœ… å¤„ç†åæ–‡æœ¬: {processed_value_2}")
    print(f"ğŸ“Š è¯†åˆ«åˆ°çš„Excel: {[excel['original_path'] for excel in resources_2['excel_files']]}")
    
    # æµ‹è¯•åœºæ™¯3ï¼šå¤šç§èµ„æºæ··åˆï¼ˆåŒ…æ‹¬MinIOè·¯å¾„ï¼‰
    test_value_3 = """
    æŠ¥å‘Šæ‘˜è¦ï¼šå›¾ç‰‡è·¯å¾„/path/image.pngå’Œæ•°æ®è¡¨data/report.xlsx
    
    MinIOå›¾ç‰‡ï¼š/bisheng/knowledge/images/123/test.jpg
    ä¸´æ—¶å›¾ç‰‡ï¼š/tmp-dir/temp/demo.png
    MinIO Excelï¼š/bisheng/reports/data.xlsx
    
    | é¡¹ç›® | æ•°å€¼ |
    |------|------|
    | A    | 100  |
    | B    | 200  |
    
    è¿˜æœ‰ç½‘ç»œå›¾ç‰‡https://example.com/chart.jpg
    """
    print(f"\nğŸ“ åŸå§‹æ–‡æœ¬: {test_value_3}")
    
    processed_value_3, resources_3 = node._extract_and_download_resources(test_value_3)
    print(f"âœ… å¤„ç†åæ–‡æœ¬: {processed_value_3}")
    print(f"ğŸ–¼ï¸ è¯†åˆ«åˆ°çš„å›¾ç‰‡: {len(resources_3['images'])} ä¸ª")
    print(f"ğŸ“Š è¯†åˆ«åˆ°çš„Excel: {len(resources_3['excel_files'])} ä¸ª") 
    print(f"ğŸ“‹ è¯†åˆ«åˆ°çš„è¡¨æ ¼: {len(resources_3['markdown_tables'])} ä¸ª")
    
    # æ˜¾ç¤ºè¯†åˆ«åˆ°çš„èµ„æºè¯¦æƒ…
    for i, img in enumerate(resources_3['images']):
        print(f"  å›¾ç‰‡{i+1}: {img['original_path']} -> {img['type']}")
    for i, excel in enumerate(resources_3['excel_files']):
        print(f"  Excel{i+1}: {excel['original_path']} -> {excel['type']}")
    
    # æµ‹è¯•åœºæ™¯4ï¼šå¤æ‚æ··åˆå†…å®¹ï¼ˆä¸€æ®µè¯ä¸­å¤šç§èµ„æºï¼‰
    test_value_4 = """
    ç»¼åˆåˆ†ææŠ¥å‘Šï¼šé¦–å…ˆæŸ¥çœ‹/bisheng/charts/overview.pngæ¦‚è§ˆå›¾ï¼Œ
    ç„¶åå‚è€ƒ/tmp-dir/data/sales.xlsxé”€å”®æ•°æ®ï¼Œæœ€åæ˜¯ç»Ÿè®¡è¡¨æ ¼ï¼š
    
    | å­£åº¦ | é”€å”®é¢ | å¢é•¿ç‡ |
    |------|-------|--------|
    | Q1   | 100ä¸‡ | 10%    |
    | Q2   | 120ä¸‡ | 20%    |
    
    è¡¥å……å›¾è¡¨https://example.com/trends.jpgæ˜¾ç¤ºè¶‹åŠ¿ï¼Œ
    è¯¦ç»†æ•°æ®è§report.xlsxæ–‡ä»¶åˆ†æã€‚
    """
    print(f"\nğŸ“ æµ‹è¯•åœºæ™¯4 - å¤æ‚æ··åˆå†…å®¹:")
    print(f"åŸå§‹æ–‡æœ¬: {test_value_4}")
    
    processed_value_4, resources_4 = node._extract_and_download_resources(test_value_4)
    print(f"âœ… å¤„ç†åæ–‡æœ¬: {processed_value_4}")
    print(f"ğŸ” èµ„æºç»Ÿè®¡:")
    print(f"  - å›¾ç‰‡: {len(resources_4['images'])} ä¸ª")
    print(f"  - Excel: {len(resources_4['excel_files'])} ä¸ª")
    print(f"  - è¡¨æ ¼: {len(resources_4['markdown_tables'])} ä¸ª")
    
    # æ˜¾ç¤ºå¤„ç†åçš„å ä½ç¬¦åˆ†å¸ƒ
    print(f"\nğŸ¯ å ä½ç¬¦åˆ†å¸ƒ:")
    for i, img in enumerate(resources_4['images']):
        print(f"  {img['placeholder']} â† {img['original_path']}")
    for i, excel in enumerate(resources_4['excel_files']):
        print(f"  {excel['placeholder']} â† {excel['original_path']}")
    for i, table in enumerate(resources_4['markdown_tables']):
        print(f"  {table['placeholder']} â† Markdownè¡¨æ ¼")
    
    return True


if __name__ == "__main__":
    test_report_node_scenario()
